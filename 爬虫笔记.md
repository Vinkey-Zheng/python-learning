# 几个重要模块

前情提要

```python
import requests # 获取页面
import pprint # 打印
import urllib
from urllib import parse # urllib模块中的解析模块
from pyquery import PyQuery as pq # pq.text()只保留文本
```

列表表达式

```python
a_List = [x * x for x in a_range] # [表达式 变量 in 范围]
```

生成器

```python
yield迭代器，可以先初步理解跟return差不多的东西，但是不一样
html = get_html()
res = parase_html(html)
print(res)  # 生成器对象
# 结果 <generator object parase_html at 0x0000021130365270>
print(next(res))
# 开始打印
```

再来看一个例子

```python
def foo():
    print("starting...")
    while True:
        res = yield 4
        print("res:",res)
g = foo() # 不会打印，只是得出来一个生成器对象
print(next(g)) # 开始打印，返回是4，然后退出
print("*"*20)
print(next(g)) # 因为已经退出了，所以不会返回4，而是None
# 如果在执行next()，又会return一个4，所以下一个打印出来又是4

结果：
starting...
4
********************
res: None
4
```

来看看整块获取网页的代码，用到requests

```python
def get_html():
    url
    response = requests.get(url=url) # 一般用get获取
    res = response.content  # 二进制文件,打印出来有'b',表示的是二进制bytes
    #print(type(res))
    res = response.text  # 字符串
    #print(type(res)) # str
    res = response.json() # 字典
    #print(res)
    return res
```

上面提到了requests是get网页，但其实他还有其他的用法

```python
# 防止别人知道我是爬虫
urllib.request.Request(url=url, data(bytes)=data, headers=headers,method="post")
# 尤其需要user-agent
urllib.request.urllib.urlopen('http://httpbin.org/post')

```

解析数据，用到pyquery，yield

```python
def parase_html(html):
    cards = html["data"]["cards"] # 这些是在微博network元素中看到的一些网页数据
    for card in cards: # 循环遍历
        xinna = {} #先建立一个空字典
        mblog = card["mblog"] # card里面又有mlog标签
        # pq().text()只保留文本,去除html标签
        xinna["内容"] = pq(mblog["text"]).text()
        xinna["评论"] = mblog["comments_count"]
        # 字符串格式化的方法
        # print(f"content:{con},comment:{comment}") # 类似的还有r(不转义字符),b(二进制)
        print(xinna)
        yield xinna
```

重点来看一下parse模块

```python
lis = doc('h2.content-title').items()
for li in lis:
    print(li.text())
    
data = bytes(urllib.parse.urlencode({"hello": "world"}), encoding = 'utf-8')
```

<img src="C:\Users\86135\AppData\Roaming\Typora\typora-user-images\image-20220128222305662.png" alt="image-20220128222305662" style="zoom:50%;" />

urlib.parse.urlencode() 将dict类型参数转化为query_string格式（key=value&key=value），并且将中文转码，最终会转换为bytes(字节流)